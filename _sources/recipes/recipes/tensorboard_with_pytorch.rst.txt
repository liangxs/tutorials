
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "recipes/recipes/tensorboard_with_pytorch.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_recipes_recipes_tensorboard_with_pytorch.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_recipes_recipes_tensorboard_with_pytorch.py:


How to use TensorBoard with PyTorch
===================================
TensorBoard is a visualization toolkit for machine learning experimentation. 
TensorBoard allows tracking and visualizing metrics such as loss and accuracy, 
visualizing the model graph, viewing histograms, displaying images and much more. 
In this tutorial we are going to cover TensorBoard installation, 
basic usage with PyTorch, and how to visualize data you logged in TensorBoard UI.

Installation
----------------------
PyTorch should be installed to log models and metrics into TensorBoard log 
directory. The following command will install PyTorch 1.4+ via 
Anaconda (recommended):

.. code-block:: sh

   $ conda install pytorch torchvision -c pytorch 
   

or pip

.. code-block:: sh

   $ pip install torch torchvision

.. GENERATED FROM PYTHON SOURCE LINES 30-36

Using TensorBoard in PyTorch
-----------------------------

Let’s now try using TensorBoard with PyTorch! Before logging anything, 
we need to create a ``SummaryWriter`` instance.


.. GENERATED FROM PYTHON SOURCE LINES 36-41

.. code-block:: Python


    import torch
    from torch.utils.tensorboard import SummaryWriter
    writer = SummaryWriter()


.. GENERATED FROM PYTHON SOURCE LINES 42-44

Writer will output to ``./runs/`` directory by default.


.. GENERATED FROM PYTHON SOURCE LINES 47-59

Log scalars
-----------

In machine learning, it’s important to understand key metrics such as 
loss and how they change during training. Scalar helps to save 
the loss value of each training step, or the accuracy after each epoch. 

To log a scalar value, use 
``add_scalar(tag, scalar_value, global_step=None, walltime=None)``. 
For example, lets create a simple linear regression training, and 
log loss value using ``add_scalar``


.. GENERATED FROM PYTHON SOURCE LINES 59-80

.. code-block:: Python


    x = torch.arange(-5, 5, 0.1).view(-1, 1)
    y = -5 * x + 0.1 * torch.randn(x.size())

    model = torch.nn.Linear(1, 1)
    criterion = torch.nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)

    def train_model(iter):
        for epoch in range(iter):
            y1 = model(x)
            loss = criterion(y1, y)
            writer.add_scalar("Loss/train", loss, epoch)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        
    train_model(10)
    writer.flush()



.. GENERATED FROM PYTHON SOURCE LINES 81-89

Call ``flush()`` method to make sure that all pending events 
have been written to disk.

See `torch.utils.tensorboard tutorials <https://pytorch.org/docs/stable/tensorboard.html>`_ 
to find more TensorBoard visualization types you can log.

If you do not need the summary writer anymore, call ``close()`` method.


.. GENERATED FROM PYTHON SOURCE LINES 89-92

.. code-block:: Python


    writer.close()


.. GENERATED FROM PYTHON SOURCE LINES 93-122

Run TensorBoard
----------------

Install TensorBoard through the command line to visualize data you logged

.. code-block:: sh

   pip install tensorboard


Now, start TensorBoard, specifying the root log directory you used above. 
Argument ``logdir`` points to directory where TensorBoard will look to find 
event files that it can display. TensorBoard will recursively walk 
the directory structure rooted at ``logdir``, looking for ``.*tfevents.*`` files.

.. code-block:: sh

   tensorboard --logdir=runs

Go to the URL it provides OR to `http://localhost:6006/ <http://localhost:6006/>`_

.. image:: ../../_static/img/thumbnails/tensorboard_scalars.png
   :scale: 40 %

This dashboard shows how the loss and accuracy change with every epoch. 
You can use it to also track training speed, learning rate, and other 
scalar values. It’s helpful to compare these metrics across different 
training runs to improve your model.


.. GENERATED FROM PYTHON SOURCE LINES 125-131

Learn More
----------------------------

-  `torch.utils.tensorboard <https://pytorch.org/docs/stable/tensorboard.html>`_ docs
-  `Visualizing models, data, and training with TensorBoard <https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html>`_ tutorial



.. _sphx_glr_download_recipes_recipes_tensorboard_with_pytorch.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: tensorboard_with_pytorch.ipynb <tensorboard_with_pytorch.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: tensorboard_with_pytorch.py <tensorboard_with_pytorch.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: tensorboard_with_pytorch.zip <tensorboard_with_pytorch.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
